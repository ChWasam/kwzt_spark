version: '3.8'

services:
  kafka:
    image: apache/kafka:latest
    container_name: kafka-broker
    hostname: kafka
    ports:
      - "9092:9092"    # Kafka broker port
      - "9093:9093"    # Controller port (KRaft)
    environment:
      # KRaft mode configuration (no Zookeeper)
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_NUM_PARTITIONS: 3
      # Auto-create topics
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    volumes:
      - kafka_data:/var/lib/kafka/data
    networks:
      - kafka_network

  producer:
    build:
      context: ./producer
      dockerfile: Dockerfile
    container_name: kafka-producer
    depends_on:
      kafka:
        condition: service_started
    environment:
      KAFKA_BROKER: kafka:9092
      KAFKA_TOPIC: transactions
      DATA_FILE: /data/transactions.csv
      BATCH_SIZE: 10000        # Send 10k records at a time
      BATCH_DELAY: 5           # Wait 5 seconds between batches
    volumes:
      - ./data:/data:ro        # Mount data folder as read-only
    networks:
      - kafka_network
    restart: on-failure
  consumer:
    build:
      context: ./consumer
      dockerfile: Dockerfile
    container_name: kafka-consumer
    depends_on:
      kafka:
        condition: service_started
    environment:
      KAFKA_BROKER: kafka:9092
      KAFKA_TOPIC: transactions
      KAFKA_GROUP_ID: transaction-consumer-group
      OUTPUT_FILE: /data/received_transactions.csv
    volumes:
      - ./data:/data           # Mount data folder for writing
    networks:
      - kafka_network
    restart: on-failure

  pyspark:
    image: jupyter/pyspark-notebook:spark-3.5.0
    container_name: pyspark-jupyter
    ports:
      - "8888:8888"    # Jupyter Lab
      - "4040:4040"    # Spark UI
    depends_on:
      kafka:
        condition: service_started
    environment:
      KAFKA_BROKER: kafka:9092
      KAFKA_TOPIC: transactions
      JUPYTER_ENABLE_LAB: "yes"
      GRANT_SUDO: "yes"
    volumes:
      - ./notebooks:/home/jovyan/work    # Mount notebooks folder
      - ./data:/home/jovyan/data:ro      # Mount data folder as read-only
    networks:
      - kafka_network
    command: start-notebook.sh --NotebookApp.token='' --NotebookApp.password=''


networks:
  kafka_network:
    driver: bridge
    name: kafka_network

volumes:
  kafka_data:
    driver: local
